<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Automerge-RS on Automerge-RS Development</title>
    <link>http://inkandswitch.github.io/automerge-rs/</link>
    <description>Recent content in Automerge-RS on Automerge-RS Development</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Jan 2021 09:55:33 -0800</lastBuildDate>
    
	<atom:link href="http://inkandswitch.github.io/automerge-rs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>LocalChange Results, Alex Rejoins</title>
      <link>http://inkandswitch.github.io/automerge-rs/post/localchange-results/</link>
      <pubDate>Tue, 19 Jan 2021 09:55:33 -0800</pubDate>
      
      <guid>http://inkandswitch.github.io/automerge-rs/post/localchange-results/</guid>
      <description>LocalChange improves several benchmarks 35% In our last update we described a performance optimization we wanted to make which we suspected would improve our performance by shiftng responsibility for tracking changes from the backend of the library to the frontend. We&amp;rsquo;re pleased to report that the localChange branch has been merged and is showing good results on the benchmarking front.
    automerge1  automerge1  automergeWASM automergeWASM     Version 09-08-2020 01-07-2021 09-08-2020 01-07-2021   [B1.</description>
      <content>&lt;h2 id=&#34;localchange-improves-several-benchmarks-35&#34;&gt;LocalChange improves several benchmarks 35%&lt;/h2&gt;
&lt;p&gt;In our &lt;a href=&#34;https://inkandswitch.github.io/automerge-rs/post/towards-production/&#34;&gt;last update&lt;/a&gt; we described a performance optimization we wanted to make which we suspected would improve our performance by shiftng responsibility for tracking changes from the backend of the library to the frontend. We&amp;rsquo;re pleased to report that the &lt;code&gt;localChange&lt;/code&gt; branch has been merged and is showing good results on the benchmarking front.&lt;/p&gt;


&lt;figure&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;automerge1  &lt;/th&gt;
&lt;th&gt;automerge1 &lt;/th&gt;
&lt;th&gt;automergeWASM&lt;/th&gt;
&lt;th&gt;automergeWASM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Version&lt;/td&gt;
&lt;td&gt;09-08-2020&lt;/td&gt;
&lt;td&gt;01-07-2021&lt;/td&gt;
&lt;td&gt;09-08-2020&lt;/td&gt;
&lt;td&gt;01-07-2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B1.2] Insert string of length N (time)&lt;/td&gt;
&lt;td&gt;441 ms&lt;/td&gt;
&lt;td&gt;288 ms&lt;/td&gt;
&lt;td&gt;35 ms&lt;/td&gt;
&lt;td&gt;22 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B1.4] Insert N characters at random positions (time)&lt;/td&gt;
&lt;td&gt;947 ms&lt;/td&gt;
&lt;td&gt;164 ms&lt;/td&gt;
&lt;td&gt;224 ms&lt;/td&gt;
&lt;td&gt;164 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B3.1] 20√N clients concurrently set number in Map (time)&lt;/td&gt;
&lt;td&gt;516 ms&lt;/td&gt;
&lt;td&gt;492 ms&lt;/td&gt;
&lt;td&gt;8 ms&lt;/td&gt;
&lt;td&gt;8 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;/figure&gt;


&lt;p&gt;These show significant improvements on test &lt;code&gt;B1.2&lt;/code&gt; and &lt;code&gt;B1.4&lt;/code&gt; as both of these tests hammer the  &lt;code&gt;applyLocalChange&lt;/code&gt; path and no change was expected on &lt;code&gt;B3.1&lt;/code&gt; as it relies only on &lt;code&gt;applyChanges&lt;/code&gt; and does no local change transform.&lt;/p&gt;
&lt;p&gt;Also the hard work by Martin Kleppmann can be seen in the greatly improved numbers in automerge1 over this timeframe.&lt;/p&gt;
&lt;h2 id=&#34;project-initiator-alex-good-returns-full-time&#34;&gt;Project initiator Alex Good returns full-time&lt;/h2&gt;
&lt;p&gt;The first version of Automerge-RS was written by &lt;a href=&#34;https://github.com/alexjg&#34;&gt;Alex Good&lt;/a&gt;, who we teamed up with to build the first version of Automerge-RS last spring.
We&amp;rsquo;re pleased to say that Alex is back with us on the team working full time on the push to get &lt;code&gt;automerge-rs&lt;/code&gt; to a 1.0 release.  He has already cleaned up the tests, reorganized the code across the &lt;code&gt;automerge-protocol&lt;/code&gt; package and merged a huge rewrite of the &lt;code&gt;automerge-frontend&lt;/code&gt; crate.&lt;/p&gt;
&lt;h2 id=&#34;blockers-for-a-10-release&#34;&gt;Blockers for a 1.0 release&lt;/h2&gt;
&lt;p&gt;Currently there are two projects that stand as hard blockers for a release of &lt;code&gt;automerge-wasm&lt;/code&gt; simultaneous automerge 1.0.&lt;/p&gt;
&lt;p&gt;First the whole document compression mode is not yet implemented in rust.  This method takes a stack of changes, does the column compression algorithm on the changes itself, and then merges the ops across all changes and compresses them as well.  All the tests currently pass without this feature but if a document were saved in the js version currently it could not be loaded in the wasm version.&lt;/p&gt;
&lt;p&gt;Second &lt;code&gt;automerge-wasm&lt;/code&gt; needs to be packaged properly.  Currently there is no official packaging, and users need to compile the wasm manually to make use of it.&lt;/p&gt;
&lt;h2 id=&#34;next-steps-in-performance-work&#34;&gt;Next steps in performance work&lt;/h2&gt;
&lt;p&gt;One issue that needs to be addressed is that the &lt;code&gt;wasm-pack&lt;/code&gt; binary throws out function names when doing a profile build.  This is a &lt;a href=&#34;https://github.com/rustwasm/wasm-pack/issues/797&#34;&gt;known issue&lt;/a&gt; but the workarounds have not worked for us yet.  Without this we have to base our profiling on debug builds which will sometimes cause us to focus on tuning up code that the compile already knows how to optimize but isn&amp;rsquo;t.  But even with this lack of visibility in profiling it&amp;rsquo;s starting to look like the js/wasm call interface is starting to be the problem.  Currently JS objects like the &lt;code&gt;UncompressedChange&lt;/code&gt; and the &lt;code&gt;Patch&lt;/code&gt; object get converted into a json string and then parsed as the intermediary on both the call and return value for each function call.  Interestingly binary changes do not do this as they are &amp;hellip; well &amp;hellip; just binary.  The only cost is copying them directly between js memory and wasm memory.  This is part of the reason why test &lt;code&gt;B3.1&lt;/code&gt; is so very fast.   Alternate ways to pass data back and forth between the layers is being looked into.&lt;/p&gt;
&lt;p&gt;In furtherance of this, Alex is currently duplicating the benchmark suite in pure rust so we can get a better idea of how much of the problem is the js/wasm interface.&lt;/p&gt;
&lt;p&gt;Most of the tests when run with 10x the data take about 10x the time.  There are 3 tests showing much worse numbers than they should at larger sizes.  These need to be looked into and remedied, hopefully being easy wins for performance.&lt;/p&gt;


&lt;figure&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;automerge1&lt;/th&gt;
&lt;th&gt;automerge1&lt;/th&gt;
&lt;th&gt;automergeWASM&lt;/th&gt;
&lt;th&gt;automergeWASM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Version&lt;/td&gt;
&lt;td&gt;N=1000&lt;/td&gt;
&lt;td&gt;N=10000&lt;/td&gt;
&lt;td&gt;N=1000&lt;/td&gt;
&lt;td&gt;N=10000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B1.3] Prepend N characters (time)&lt;/td&gt;
&lt;td&gt;2080 ms&lt;/td&gt;
&lt;td&gt;270069 ms&lt;/td&gt;
&lt;td&gt;175 ms&lt;/td&gt;
&lt;td&gt;3624 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B1.5] Insert N words at random positions (time)&lt;/td&gt;
&lt;td&gt;1619 ms&lt;/td&gt;
&lt;td&gt;46180 ms&lt;/td&gt;
&lt;td&gt;404 ms&lt;/td&gt;
&lt;td&gt;26491 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B1.10]  Prepend N numbers (time)&lt;/td&gt;
&lt;td&gt;2136 ms&lt;/td&gt;
&lt;td&gt;273761 ms&lt;/td&gt;
&lt;td&gt;209 ms&lt;/td&gt;
&lt;td&gt;4664 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;/figure&gt;


</content>
    </item>
    
    <item>
      <title>Towards Production: Getting in Shape</title>
      <link>http://inkandswitch.github.io/automerge-rs/post/towards-production/</link>
      <pubDate>Fri, 18 Dec 2020 09:55:33 -0800</pubDate>
      
      <guid>http://inkandswitch.github.io/automerge-rs/post/towards-production/</guid>
      <description>Behind Automerge-RS In 2017, Ink &amp;amp; Switch decided to collaborate with Martin Kleppmann to see if we could build an easy to use CRDT in javascript based on Martin&amp;rsquo;s research. By and large, I think we were successful, which can be seen in Automerge v0.14.1.
While we hit the goals of being a correct CRDT that was easy to use, there were a number of shortcomings. It was too slow, and as every change in the history was stored completely in an uncompressed format, the footprint of a document was too large.</description>
      <content>&lt;h3 id=&#34;behind-automerge-rs&#34;&gt;Behind Automerge-RS&lt;/h3&gt;
&lt;p&gt;In 2017, Ink &amp;amp; Switch decided to collaborate with Martin Kleppmann to see if we could build an easy to use CRDT in javascript based on Martin&amp;rsquo;s research.  By and large, I think we were successful, which can be seen in &lt;a href=&#34;https://github.com/automerge/automerge&#34;&gt;Automerge v0.14.1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While we hit the goals of being a correct CRDT that was easy to use, there were a number of shortcomings.  It was too slow, and as every change in the history was stored completely in an uncompressed format, the footprint of a document was too large.&lt;/p&gt;
&lt;p&gt;Martin began work on the &lt;a href=&#34;https://github.com/automerge/automerge/tree/performance&#34;&gt;performance branch&lt;/a&gt; to address these problems.  The new, but unreleased, version of Automerge is much more robust, and solves many of the performance problems of the original.  But most importantly creates an extremely efficiently compressed binary format that makes radical improvements on the memory and storage footprint of these documents.  This performance branch is very solid for day-to-day use but not recommended for anything in production as tweaks to the binary format and api calls are still happening regularly.&lt;/p&gt;
&lt;p&gt;Early this year, I decided that Automerge was ready move from its proof-of-concept javascript-only implementation to the cross-platform, high performance implementation I&amp;rsquo;ve always desired. To accomplish this, &lt;a href=&#34;https://github.com/alexjg&#34;&gt;Alex Good&lt;/a&gt; and I teamed up to write &lt;a href=&#34;https://github.com/automerge/automerge-rs&#34;&gt;AutomergeRS&lt;/a&gt;, an API compatible implementation of Automerge&amp;rsquo;s Backend half, implemented in Rust, with WASM bindings.  The package also contains an early implementation of a rust-native frontend, and C bindings for the backend, to enable Frontend implementations in other languages such as Swift.  While there is not an official npm package for AutomergeRS yet, I have &lt;a href=&#34;https://github.com/orionz/automerge/tree/wasm-node&#34;&gt;rolled one for myself&lt;/a&gt;.  It only works in Node, as the wasm loading is async in the browser and would require the library to be wrapped in a promise.&lt;/p&gt;
&lt;p&gt;We modified a &lt;a href=&#34;https://github.com/orionz/automerge-perf&#34;&gt;pre existing performance test&lt;/a&gt; made by Martin to ensure we met or exceeded the performance of the javascript performance branch.&lt;/p&gt;


&lt;figure&gt;


&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ node automerge-text.js
&lt;span class=&#34;nv&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;js   &lt;span class=&#34;nv&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2000&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;76358ms
&lt;span class=&#34;nv&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;wasm &lt;span class=&#34;nv&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2000&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;8491ms
&lt;span class=&#34;nv&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;js   &lt;span class=&#34;nv&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;43054ms
&lt;span class=&#34;nv&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;wasm &lt;span class=&#34;nv&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;  &lt;span class=&#34;nv&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;17044ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;/figure&gt;


&lt;h3 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h3&gt;
&lt;p&gt;There are many steps in getting Automerge ready for the big time. But a very important one that I am personally focused on is making sure Automerge is the performance king of CRDT&amp;rsquo;s.  That crown is currently held by &lt;a href=&#34;git@github.com:yjs/yjs.git&#34;&gt;yjs&lt;/a&gt;, an excellent CRDT that focuses specifically on collaborative text editing.  Now, there&amp;rsquo;s some apples-to-oranges issues in comparing them, as these two CRDT&amp;rsquo;s have very different goals.  Yjs is javascript only, Automerge intends to be available on all platforms.  Yjs is for managing lists (or things you can build out of lists) with a bespoke API.  Automerge allows you to manage your document as a plain old javascript object with arbitrarily nested maps and lists.  Yjs does not preserve the document history in a meaningful way, whereas Automerge preserves the entire history and allows for easy point in time recovery and branching, similar to Git.  Automerge allows you to move the CRDT portion of the document out of the render thread, or even onto a different machine, via the frontend/backend split, while Yjs just focuses on being fast enough that you shouldn&amp;rsquo;t need to.&lt;/p&gt;
&lt;p&gt;Nevertheless I wanted to see how far we needed to go to catch up and what I could learn from their approach.  We adapted an &lt;a href=&#34;https://github.com/orionz/crdt-benchmarks&#34;&gt;existing benchmark&lt;/a&gt; used to compare Yjs to other CRDTs to see what we could see.  This test suite is very comprehensive and has been invaluable to work with.  But for this post I want to cherry pick a handful of tests that I think distill the current performance story&lt;/p&gt;


&lt;figure&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;yjs&lt;/th&gt;
&lt;th&gt;automerge1&lt;/th&gt;
&lt;th&gt;automergeWASM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Version&lt;/td&gt;
&lt;td&gt;13.4.1&lt;/td&gt;
&lt;td&gt;09-08-2020&lt;/td&gt;
&lt;td&gt;09-08-2020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B1.2] Insert string of length N (time)&lt;/td&gt;
&lt;td&gt;4 ms&lt;/td&gt;
&lt;td&gt;441 ms&lt;/td&gt;
&lt;td&gt;35 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B1.4] Insert N characters at random positions (time)&lt;/td&gt;
&lt;td&gt;99 ms&lt;/td&gt;
&lt;td&gt;947 ms&lt;/td&gt;
&lt;td&gt;224 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[B3.1] 20√N clients concurrently set number in Map (time)&lt;/td&gt;
&lt;td&gt;95 ms&lt;/td&gt;
&lt;td&gt;516 ms&lt;/td&gt;
&lt;td&gt;8 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;/figure&gt;


&lt;p&gt;First, in test &lt;code&gt;[B3.1]&lt;/code&gt;, Automerge does very well with concurrency and maps.  This makes sense since Automerge supports maps natively whereas Yjs implements them on top of lists.  Second, Yjs dominates in sequential character insertions as seen in test &lt;code&gt;[B1.2]&lt;/code&gt;.  Yjs has a number of very clever optimizations around this specific scenario because text entry (its target use case) is mostly sequential and thus deserves specific optimizations.  The first is compressing spans of elementId&amp;rsquo;s with common actors and sequential counters.  In fact test &lt;code&gt;[B1.2]&lt;/code&gt; becomes a single op where Automerge creates an op per character.  The second is keeping a set of &amp;ldquo;hot&amp;rdquo; list positions cached to speed up &lt;code&gt;indexOf(elementId)&lt;/code&gt; operations which are predictable in mostly sequental text entry.&lt;/p&gt;
&lt;p&gt;Both of these are very clever optimizations that we could take advantage of but, to me, the standout test is the one that shows Automerge falling behind on random inserts.  In this scenario, neither of these optimizations play a part and as (under the hood) both are using the same Lamport Compare to do the CRDT work, we should be neck and neck.  As it stands we need to reduce our execution time by about 50% to catch up.&lt;/p&gt;
&lt;p&gt;After some aggressive profiling I was able to determine a large chunk of time was spent in memory allocations related to change request versioning.  To explain, the frontend does not generate a fully formed change.  It instead creates a &amp;lsquo;change request&amp;rsquo; which is like a change but missing four things.  It lacks the &lt;code&gt;pred&lt;/code&gt;, &lt;code&gt;startOp&lt;/code&gt;, &lt;code&gt;deps&lt;/code&gt; fields and list elementId&amp;rsquo;s.  It&amp;rsquo;s the backend&amp;rsquo;s job to fill these out before creating the cannoical change object.  The problem is that the backend needs to hold on to previous versions so that when a request says &amp;ldquo;insert after list index 7&amp;rdquo; it has to know what the state of the world was at that time to correctly traslate &lt;code&gt;7&lt;/code&gt; into an elementId.  This requires the backend to keep multiple versions of the document state in memory.  Currently we use immutable data structures so the cost to do so is low&amp;hellip; but not zero.  And in the usual case of the frontend and backend being caught up this versioning does nothing while extracting a hefty tax.&lt;/p&gt;
&lt;p&gt;I tried disabling the versioning code (which would produce wrong results when the front-end back-end get out of sync) to understand what the performance cost was and saw speedups between 15% and 30% from that alone.  This is no small matter when all I need is a total gain of 50%.  The solution is to have the frontend produce fully formed changes, complete with &lt;code&gt;pred&lt;/code&gt; and elementId&amp;rsquo;s.&lt;/p&gt;
&lt;p&gt;That change has been the subject of the &lt;a href=&#34;https://github.com/automerge/automerge/pull/291&#34;&gt;current pull request&lt;/a&gt; I have open with Automerge that I hope to have merged soon.  This would be the first time my rust work would result in a significant change to the Automerge API as up until now I&amp;rsquo;ve been trying to work entirely within the constraints laid out by Martin&amp;rsquo;s design.  With any luck this will be accepted into Automerge/performance and I&amp;rsquo;ll be back with better benchmarks next week.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/orionz/&#34;&gt;Orion Henry&lt;/a&gt;&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>